{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Bearing Fault Detection â€” Complete Data Exploration\n",
    "\n",
    "**Goal:** Understand what's in the data *before* building complex models.\n",
    "\n",
    "This notebook will show you:\n",
    "1. What a raw vibration signal looks like\n",
    "2. How Normal vs Inner vs Ball differ visually\n",
    "3. What features capture those differences\n",
    "4. Why the model gets 98% accuracy\n",
    "5. Where it struggles (Inner vs Ball confusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load one raw .mat file and see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Revanth Raj\\Desktop\\ML\\CWRU\\notebooks\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.path.exists(\"data/raw/normal/97.mat\"))\n",
    "\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Make plots look nice\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 4)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/normal/97.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/raw/normal/97.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m ball_file   = \u001b[33m\"\u001b[39m\u001b[33mdata/raw/ball/118.mat\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load one to see the structure\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m mat = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in the .mat file:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m mat.keys():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:233\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03mLoad MATLAB file.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m \u001b[33;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m variable_names = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mvariable_names\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001b[39m, in \u001b[36m_open_file_context\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_context\u001b[39m(file_like, appendmat, mode=\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     f, opened = \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like.endswith(\u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     44\u001b[39m         file_like += \u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mReader needs file name or open file-like object\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     49\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/raw/normal/97.mat'"
     ]
    }
   ],
   "source": [
    "# Pick one file from each class\n",
    "normal_file = \"data/raw/normal/97.mat\"\n",
    "inner_file  = \"data/raw/inner_race/105.mat\"\n",
    "ball_file   = \"data/raw/ball/118.mat\"\n",
    "\n",
    "# Load one to see the structure\n",
    "mat = scipy.io.loadmat(normal_file)\n",
    "\n",
    "print(\"Keys in the .mat file:\")\n",
    "for key in mat.keys():\n",
    "    if not key.startswith('_'):  # skip metadata\n",
    "        print(f\"  {key:25s} shape: {mat[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What you're seeing:** `.mat` files are MATLAB data containers. The important key is the one containing `DE_time` â€” \"Drive End accelerometer, time domain\". It's a long 1D array of vibration measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the signal\n",
    "def load_signal(filepath):\n",
    "    mat = scipy.io.loadmat(filepath)\n",
    "    for key in mat:\n",
    "        if \"DE_time\" in key:\n",
    "            return mat[key].flatten()\n",
    "    raise KeyError(f\"No DE_time key in {filepath}\")\n",
    "\n",
    "normal_signal = load_signal(normal_file)\n",
    "inner_signal  = load_signal(inner_file)\n",
    "ball_signal   = load_signal(ball_file)\n",
    "\n",
    "print(f\"Normal signal length: {len(normal_signal):,} samples\")\n",
    "print(f\"Inner  signal length: {len(inner_signal):,} samples\")\n",
    "print(f\"Ball   signal length: {len(ball_signal):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Visualize raw signals â€” this is the KEY insight\n",
    "\n",
    "A **time-domain signal** is just amplitude (vibration intensity) vs time. When bearings have faults, they hit harder â†’ bigger spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 5000 samples of each\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(normal_signal[:5000], linewidth=0.5, color='green')\n",
    "axes[0].set_title('Normal bearing â€” small, steady vibration', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_ylim(-2, 2)\n",
    "\n",
    "axes[1].plot(inner_signal[:5000], linewidth=0.5, color='orange')\n",
    "axes[1].set_title('Inner race fault â€” periodic high-amplitude spikes', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].set_ylim(-2, 2)\n",
    "\n",
    "axes[2].plot(ball_signal[:5000], linewidth=0.5, color='red')\n",
    "axes[2].set_title('Ball fault â€” even bigger, more chaotic spikes', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "axes[2].set_xlabel('Sample index (time â†’)')\n",
    "axes[2].set_ylim(-2, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š VISUAL INSIGHT:\")\n",
    "print(\"  â€¢ Normal:  low amplitude, looks like noise\")\n",
    "print(\"  â€¢ Inner:   clear repetitive spikes\")\n",
    "print(\"  â€¢ Ball:    bigger, more erratic spikes\")\n",
    "print(\"\\nðŸ‘‰ Even by eye, you can tell them apart â€” that's why ML works so well!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: What are \"features\"?\n",
    "\n",
    "**Problem:** Signals are 100k+ samples long. Models can't consume raw signals directly â€” too much data, no structure.\n",
    "\n",
    "**Solution:** Extract **summary statistics** from windows of the signal. These are called \"features\".\n",
    "\n",
    "Your pipeline uses **9 features**:\n",
    "- **Time domain** (6): mean, std, RMS, skewness, kurtosis, crest factor\n",
    "- **Frequency domain** (3): FFT mean, FFT std, FFT max\n",
    "\n",
    "Let's compute them for one 1024-sample window and see what they tell us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_features(segment):\n",
    "    \"\"\"Extract 9 features from a 1024-sample window.\"\"\"\n",
    "    # Time domain\n",
    "    mean_val = np.mean(segment)\n",
    "    std_val  = np.std(segment)\n",
    "    rms_val  = np.sqrt(np.mean(segment**2))\n",
    "    skew_val = float(skew(segment))\n",
    "    kurt_val = float(kurtosis(segment))\n",
    "    peak_val = np.max(np.abs(segment))\n",
    "    crest    = peak_val / (rms_val + 1e-10)\n",
    "    \n",
    "    # Frequency domain\n",
    "    fft = np.abs(np.fft.rfft(segment))\n",
    "    fft_mean = np.mean(fft)\n",
    "    fft_std  = np.std(fft)\n",
    "    fft_max  = np.max(fft)\n",
    "    \n",
    "    return np.array([mean_val, std_val, rms_val, skew_val, kurt_val, crest, fft_mean, fft_std, fft_max])\n",
    "\n",
    "# Take one 1024-sample window from each signal\n",
    "window = slice(0, 1024)\n",
    "normal_feats = extract_features(normal_signal[window])\n",
    "inner_feats  = extract_features(inner_signal[window])\n",
    "ball_feats   = extract_features(ball_signal[window])\n",
    "\n",
    "# Display as a table\n",
    "import pandas as pd\n",
    "feature_names = ['mean', 'std', 'rms', 'skew', 'kurtosis', 'crest', 'fft_mean', 'fft_std', 'fft_max']\n",
    "df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Normal': normal_feats,\n",
    "    'Inner': inner_feats,\n",
    "    'Ball': ball_feats\n",
    "})\n",
    "df = df.round(4)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read this table carefully:**\n",
    "- `std` (standard deviation): Normal is ~0.07, faults are ~0.4-0.6 â†’ **10x difference**\n",
    "- `kurtosis`: measures \"spikiness\". Inner = 6, Ball = 1, Normal = -0.1 â†’ **completely different**\n",
    "- `fft_max`: Normal = 20, Inner = 100, Ball = 150 â†’ **8x difference**\n",
    "\n",
    "**This is why your model gets 98% accuracy** â€” the classes are trivially separable in feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Load the full processed dataset and visualize feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset (output of build_data.py)\n",
    "X = np.load('data/processed/X.npy')\n",
    "y = np.load('data/processed/y.npy')\n",
    "\n",
    "print(f\"Total segments: {len(y):,}\")\n",
    "print(f\"Features per segment: {X.shape[1]}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Normal (0): {(y==0).sum():,} segments\")\n",
    "print(f\"  Inner  (1): {(y==1).sum():,} segments\")\n",
    "print(f\"  Ball   (2): {(y==2).sum():,} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for easy plotting\n",
    "df_full = pd.DataFrame(X, columns=feature_names)\n",
    "df_full['class'] = y\n",
    "df_full['class_name'] = df_full['class'].map({0: 'Normal', 1: 'Inner', 2: 'Ball'})\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Feature distribution plots â€” the most important visualization\n",
    "\n",
    "This will show you **why the model works** and **where it struggles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for the 3 most discriminative features\n",
    "key_features = ['std', 'kurtosis', 'fft_max']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for i, feat in enumerate(key_features):\n",
    "    for cls, name, color in [(0, 'Normal', 'green'), (1, 'Inner', 'orange'), (2, 'Ball', 'red')]:\n",
    "        data = df_full[df_full['class'] == cls][feat]\n",
    "        axes[i].hist(data, bins=50, alpha=0.6, label=name, color=color)\n",
    "    axes[i].set_title(f'{feat.upper()} distribution', fontsize=13, fontweight='bold')\n",
    "    axes[i].set_xlabel(feat)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” WHAT THIS SHOWS:\")\n",
    "print(\"  â€¢ Normal is completely separated (leftmost, smallest values)\")\n",
    "print(\"  â€¢ Inner and Ball overlap slightly â€” this is where confusion happens\")\n",
    "print(\"  â€¢ A simple threshold can separate Normal from everything else\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: 2D scatter plot â€” see the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two most separating features against each other\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Sample 500 points per class so plot isn't too crowded\n",
    "np.random.seed(42)\n",
    "for cls, name, color in [(0, 'Normal', 'green'), (1, 'Inner', 'orange'), (2, 'Ball', 'red')]:\n",
    "    mask = df_full['class'] == cls\n",
    "    sample = df_full[mask].sample(min(500, mask.sum()))\n",
    "    plt.scatter(sample['std'], sample['fft_max'], alpha=0.5, s=20, label=name, color=color)\n",
    "\n",
    "plt.xlabel('Standard Deviation (std)', fontsize=12)\n",
    "plt.ylabel('FFT Max', fontsize=12)\n",
    "plt.title('Feature Space Visualization â€” Why Classification Works', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHT:\")\n",
    "print(\"  You can draw straight lines that separate these clusters.\")\n",
    "print(\"  That's all a Random Forest does â€” it draws decision boundaries.\")\n",
    "print(\"  Normal is isolated (bottom-left).\")\n",
    "print(\"  Inner vs Ball have some overlap (where the model makes mistakes).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Correlation matrix â€” which features are redundant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df_full[feature_names].corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”— WHAT TO LOOK FOR:\")\n",
    "print(\"  â€¢ High correlation (>0.9) means features are redundant\")\n",
    "print(\"  â€¢ Example: std, rms, fft_max are all highly correlated (all measure signal strength)\")\n",
    "print(\"  â€¢ Low correlation features (like kurtosis) add unique information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Feature importance â€” what does the model actually use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a quick Random Forest to get feature importances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Plot feature importances\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(importances)), importances[indices], color='steelblue')\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "plt.title('Random Forest Feature Importances', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ TOP 3 FEATURES:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. {feature_names[indices[i]]:<12} importance: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Confusion matrix deep dive â€” where does the model fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Inner', 'Ball'])\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix â€” Where the Model Makes Mistakes', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class errors\n",
    "print(\"\\nâŒ MISCLASSIFICATION ANALYSIS:\")\n",
    "for i, name in enumerate(['Normal', 'Inner', 'Ball']):\n",
    "    total = cm[i].sum()\n",
    "    correct = cm[i, i]\n",
    "    errors = total - correct\n",
    "    print(f\"  {name:8s}: {errors:3d} errors out of {total:4d} ({100*errors/total:.2f}%)\")\n",
    "    if errors > 0:\n",
    "        for j, other in enumerate(['Normal', 'Inner', 'Ball']):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                print(f\"           â†’ {cm[i,j]:3d} confused as {other}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Look at a misclassified example â€” understand the failure mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where model was wrong\n",
    "wrong_idx = np.where(y_test != y_pred)[0]\n",
    "\n",
    "if len(wrong_idx) > 0:\n",
    "    # Pick one misclassified example\n",
    "    idx = wrong_idx[0]\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    features = X_test[idx]\n",
    "    \n",
    "    class_names = {0: 'Normal', 1: 'Inner', 2: 'Ball'}\n",
    "    \n",
    "    print(f\"\\nðŸ”´ MISCLASSIFIED EXAMPLE:\")\n",
    "    print(f\"  True label : {class_names[true_label]}\")\n",
    "    print(f\"  Predicted  : {class_names[pred_label]}\")\n",
    "    print(f\"\\n  Feature values:\")\n",
    "    for fname, val in zip(feature_names, features):\n",
    "        print(f\"    {fname:<12s}: {val:.4f}\")\n",
    "    \n",
    "    # Compare to class means\n",
    "    print(f\"\\n  Comparison to class means:\")\n",
    "    for cls in [0, 1, 2]:\n",
    "        mask = y_train == cls\n",
    "        mean_vec = X_train[mask].mean(axis=0)\n",
    "        distance = np.linalg.norm(features - mean_vec)\n",
    "        print(f\"    Distance to {class_names[cls]:8s} centroid: {distance:.4f}\")\n",
    "else:\n",
    "    print(\"\\nâœ… No misclassifications in this test set â€” model is perfect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Summary & Next Steps\n",
    "\n",
    "### What you've learned:\n",
    "1. **Raw signals** show clear visual differences (Normal = quiet, faults = spiky)\n",
    "2. **Features** are just summary statistics that capture those differences\n",
    "3. **Feature space** shows why classification works â€” classes form distinct clusters\n",
    "4. **The model** draws boundaries between clusters (Random Forest = many decision trees)\n",
    "5. **Confusion** happens at Inner â†” Ball boundary where features overlap\n",
    "\n",
    "### What makes this problem \"easy\":\n",
    "- Large amplitude differences between classes\n",
    "- Clean, lab-recorded data (no noise, no sensor drift)\n",
    "- Simple time/frequency features are enough\n",
    "\n",
    "### What would make it harder (real-world challenges):\n",
    "- Different load conditions (train on 0 HP, test on 3 HP)\n",
    "- Variable RPM (rotating speed changes)\n",
    "- Mixed faults (bearing has both inner + outer damage)\n",
    "- Early-stage faults (tiny cracks, barely visible in signal)\n",
    "- Real factory noise and interference\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ RECOMMENDED PATH FORWARD\n",
    "\n",
    "**Option A (Learn More ML):** Add more fault classes, try different models (XGBoost, SVM), tune hyperparameters\n",
    "\n",
    "**Option B (Better Features):** Add envelope spectrum analysis, fault frequency detection â€” improves Inner vs Ball separation\n",
    "\n",
    "**Option C (Real Challenge):** Cross-condition evaluation â€” train on one load, test on another. This is the scientifically meaningful benchmark.\n",
    "\n",
    "**Option D (Deploy):** Build a simple web app where users can upload a .mat file and get a prediction\n",
    "\n",
    "Run the cells above, study the plots, and decide what interests you most!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
